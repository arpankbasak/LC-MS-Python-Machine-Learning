{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3, name = \"x\")\n",
    "y = tf.Variable(4, name = \"y\")\n",
    "f = x*x*y + y+ 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings; warnings.simplefilter(\"ignore\")\n",
    "#importing important libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as  sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv(\"diffreport.csv\", sep= \",\")\n",
    "\n",
    "d1 = df.drop(\"name\", axis = 1)\n",
    "d2 = d1.drop(\"isotopes\", axis = 1)\n",
    "d3 = d2.drop(\"adduct\", axis = 1)\n",
    "d4 = d3.drop(\"tstat\", axis = 1)\n",
    "d5 = d4.drop(\"pvalue\", axis = 1)\n",
    "d6 = d5.drop(\"fold\", axis = 1)\n",
    "d7 = d6.drop(d6.columns[0], axis = 1)\n",
    "d8 = d7.drop(\"npeaks\", axis = 1)\n",
    "d9 = d8.drop(\"Eta6\", axis = 1)\n",
    "d10 = d9.drop(\"Eta8\", axis = 1)\n",
    "columns = ['mzmin', 'mzmax', 'rtmed', 'rtmin', 'rtmax', 'Eta6_0', 'Eta6_2', 'Eta6_3', 'Eta8.1', 'Eta82']\n",
    "df1 = pd.DataFrame(d10, columns = columns)\n",
    "df1.rename(columns = {'Eta6_0': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\Kundai\\scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype = tf.float32, name = \"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session()  as sess:\n",
    "    theta_value = theta.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 28438.5\n",
      "Epoch 100 MSE= nan\n",
      "Epoch 200 MSE= nan\n",
      "Epoch 300 MSE= nan\n",
      "Epoch 400 MSE= nan\n",
      "Epoch 500 MSE= nan\n",
      "Epoch 600 MSE= nan\n",
      "Epoch 700 MSE= nan\n",
      "Epoch 800 MSE= nan\n",
      "Epoch 900 MSE= nan\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32,  name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1),dtype = tf.float32, name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n +1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred -y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = 2/m *tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta-learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session()as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE=\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using an optimizer\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "# Momentum optimizer is faster\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate,momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using mini batch gradient descent\n",
    "X = tf.placeholder(tf.float32, shape = (None, n +1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32,shape = (None, n +1), name = \"y\") \n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#executon phase, fetch the mini batches one by one\n",
    "theta = tf.Variable(tf.random_uniform([n +1, 1], -1.0, 1.0), name = \"theta\")\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for batch_index in range (n_batches):\n",
    "    X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "    if batch_index % 10 == 0:\n",
    "        summary_str = mse_summary.eval(feed_dict = {X: X_batch, y:y_batch})\n",
    "        step = epoch * n_batches + batch_index\n",
    "        file_writer.add_summary(summary_str, step)\n",
    "        sess.run(training_op, feed_dict = {X: X_batch, y:y_batch})\n",
    "\n",
    "\n",
    "def fetch_batch(epoch,batch_index, batch_size):\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        X_batch, y_batch= fetch_batch(epoch,batch_index,  batch_size)\n",
    "        sess.run(training_op, feed_dict = {X: X_batch, y:y_batch})\n",
    "        save_path = saver.save(sess, \"/tmp/my_model.ckpt\")  # creating a checkpoint to save model incase it crashes\n",
    "        \n",
    "        best_theta = theta.eval()\n",
    "        save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#restoring a tensor graph and stored variables\n",
    "saver = tf.train.import_meta_graph(\"/tmp./my_model_final.ckpt.meta\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Graph and Training Curves Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "\n",
    "\n",
    "# code at the end of the construction phase\n",
    "mse_summary = tf.summary.scalar('MSE', mse) # creates node in graph and stores MSE value to TensorBoard\n",
    "file_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
